{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc197800",
   "metadata": {},
   "source": [
    "# ITR: generate clusters based on semantic similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f4f514",
   "metadata": {},
   "source": [
    "**Tangxiaoxue Zhang**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e34881",
   "metadata": {},
   "source": [
    "## Method's Current Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9cf544",
   "metadata": {},
   "source": [
    "A common “semantic clustering” workflow in recent research is: (i) represent each item (text, image, or image–text pair) as a dense embedding from a pretrained model, then (ii) run a clustering algorithm (often k-means) in that vector space to discover groups that share meaning, topic, or latent structure. This is attractive because embeddings compress high-dimensional raw data (pixels or tokens) into a geometry where semantic similarity is more likely to correspond to distance.\n",
    "\n",
    "In computer vision and multimodal work, embeddings are often treated as a way to “name” or “index” concept neighborhoods. For example, MoDE (Ma et al., 2024) clusters large-scale CLIP-style training data so that each “data expert” specializes on one semantic cluster, reducing noise from mismatched image–caption pairs; practically, it uses caption-side embeddings to cluster the dataset, then trains separate models per cluster and ensembles them at inference time.  This is a strong example of semantic clustering as data organization: clusters become actionable units for model training, routing, and analysis.\n",
    "\n",
    "In NLP, the same logic appears in embedding-based clustering for discovering latent intents or topics without labels. Park et al. (2024) explicitly compare utterance embedding models (e.g., MiniLM / MPNet / SimCSE) and multiple clustering methods (including k-means) for intent induction. Their main takeaway is directly relevant to my experience when testing with my data: clustering outcomes depend heavily on both the embedding space and the clustering algorithm, so it’s not enough to “just run k-means,  I need to evaluate robustness and metric sensitivity.  \n",
    "\n",
    "A third line of work focuses on which embedding pooling strategy produces clusterable representations. Ortakci (2024) tests SBERT variants and pooling methods (CLS / mean / max) across many text clustering tasks and shows that there is no universal “best SBERT,” but mean pooling is most consistently effective in their benchmark set.  This matters for my project because “semantic similarity” is only as good as the embedding: if the embedding model collapses distinctions that humans care about, k-means will appear unstable or misaligned with category labels.\n",
    "\n",
    "How this inform my project: my goal is to form semantically close groups of images that plausibly co-occur “in reality” (shared contexts, shared cultural meaning, similar concepts). Embedding + k-means is widely used for exactly that: it produces a data-driven semantic partition that can be used as (a) a control/stratification variable, (b) a sampling tool for constructing matched sets, or (c) a way to test whether memorability patterns are driven by semantic neighborhoods rather than isolated object labels. At the same time, the literature emphasizes that stability is not guaranteed—it must be measured and engineered (e.g., pooling choice, normalization, multiple restarts, stability metrics). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35fa12d",
   "metadata": {},
   "source": [
    "## Test on my data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6079c94a",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cb9ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bottom-up Category (Human Raters)</th>\n",
       "      <th>Top-down Category (WordNet)</th>\n",
       "      <th>Top-down Category (manual selection)</th>\n",
       "      <th>Dimension_1</th>\n",
       "      <th>Dimension_2</th>\n",
       "      <th>Dimension_3</th>\n",
       "      <th>Dimension_4</th>\n",
       "      <th>Dimension_5</th>\n",
       "      <th>Dimension_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Dimension_291</th>\n",
       "      <th>Dimension_292</th>\n",
       "      <th>Dimension_293</th>\n",
       "      <th>Dimension_294</th>\n",
       "      <th>Dimension_295</th>\n",
       "      <th>Dimension_296</th>\n",
       "      <th>Dimension_297</th>\n",
       "      <th>Dimension_298</th>\n",
       "      <th>Dimension_299</th>\n",
       "      <th>Dimension_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>animal</td>\n",
       "      <td>animal</td>\n",
       "      <td>animal</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.068236</td>\n",
       "      <td>-0.028361</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>-0.065438</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045665</td>\n",
       "      <td>0.011164</td>\n",
       "      <td>-0.005354</td>\n",
       "      <td>0.035327</td>\n",
       "      <td>-0.001382</td>\n",
       "      <td>0.077301</td>\n",
       "      <td>-0.083461</td>\n",
       "      <td>0.064104</td>\n",
       "      <td>-0.004183</td>\n",
       "      <td>0.046304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>home decor</td>\n",
       "      <td>0.056792</td>\n",
       "      <td>-0.063938</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>0.045321</td>\n",
       "      <td>-0.038369</td>\n",
       "      <td>0.048631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002180</td>\n",
       "      <td>0.041572</td>\n",
       "      <td>-0.017164</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.051482</td>\n",
       "      <td>-0.040223</td>\n",
       "      <td>-0.066239</td>\n",
       "      <td>0.016329</td>\n",
       "      <td>-0.076589</td>\n",
       "      <td>-0.009422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accordion</td>\n",
       "      <td>musical instrument</td>\n",
       "      <td>musical instrument</td>\n",
       "      <td>musical instrument</td>\n",
       "      <td>0.027205</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>-0.025440</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>-0.027733</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>0.074330</td>\n",
       "      <td>-0.086789</td>\n",
       "      <td>-0.115503</td>\n",
       "      <td>0.019062</td>\n",
       "      <td>0.069380</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>-0.006804</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.036277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acorn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fruit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034074</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>-0.079977</td>\n",
       "      <td>0.064698</td>\n",
       "      <td>-0.002513</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>0.023666</td>\n",
       "      <td>-0.046211</td>\n",
       "      <td>-0.060001</td>\n",
       "      <td>0.047634</td>\n",
       "      <td>-0.036336</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>-0.053503</td>\n",
       "      <td>-0.013425</td>\n",
       "      <td>0.059680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>air conditioner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>electronic device</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>-0.031035</td>\n",
       "      <td>-0.008351</td>\n",
       "      <td>-0.013928</td>\n",
       "      <td>0.066164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048569</td>\n",
       "      <td>0.047054</td>\n",
       "      <td>-0.002966</td>\n",
       "      <td>0.038435</td>\n",
       "      <td>0.027077</td>\n",
       "      <td>-0.031518</td>\n",
       "      <td>-0.092717</td>\n",
       "      <td>0.145555</td>\n",
       "      <td>0.015335</td>\n",
       "      <td>0.023629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Bottom-up Category (Human Raters)  \\\n",
       "1         aardvark                            animal   \n",
       "2           abacus                               NaN   \n",
       "3        accordion                musical instrument   \n",
       "4            acorn                               NaN   \n",
       "5  air conditioner                               NaN   \n",
       "\n",
       "  Top-down Category (WordNet) Top-down Category (manual selection)  \\\n",
       "1                      animal                               animal   \n",
       "2                         NaN                           home decor   \n",
       "3          musical instrument                   musical instrument   \n",
       "4                       fruit                                  NaN   \n",
       "5                         NaN                    electronic device   \n",
       "\n",
       "   Dimension_1  Dimension_2  Dimension_3  Dimension_4  Dimension_5  \\\n",
       "1     0.002518     0.068236    -0.028361     0.166795    -0.065438   \n",
       "2     0.056792    -0.063938    -0.001322     0.045321    -0.038369   \n",
       "3     0.027205     0.002443    -0.025440     0.022057    -0.027733   \n",
       "4     0.034074     0.006323    -0.079977     0.064698    -0.002513   \n",
       "5     0.001522     0.003388    -0.031035    -0.008351    -0.013928   \n",
       "\n",
       "   Dimension_6  ...  Dimension_291  Dimension_292  Dimension_293  \\\n",
       "1     0.031492  ...      -0.045665       0.011164      -0.005354   \n",
       "2     0.048631  ...      -0.002180       0.041572      -0.017164   \n",
       "3     0.004925  ...       0.018821       0.074330      -0.086789   \n",
       "4    -0.019950  ...       0.012923       0.023666      -0.046211   \n",
       "5     0.066164  ...      -0.048569       0.047054      -0.002966   \n",
       "\n",
       "   Dimension_294  Dimension_295  Dimension_296  Dimension_297  Dimension_298  \\\n",
       "1       0.035327      -0.001382       0.077301      -0.083461       0.064104   \n",
       "2      -0.052926      -0.051482      -0.040223      -0.066239       0.016329   \n",
       "3      -0.115503       0.019062       0.069380       0.001089      -0.006804   \n",
       "4      -0.060001       0.047634      -0.036336       0.012826      -0.053503   \n",
       "5       0.038435       0.027077      -0.031518      -0.092717       0.145555   \n",
       "\n",
       "   Dimension_299  Dimension_300  \n",
       "1      -0.004183       0.046304  \n",
       "2      -0.076589      -0.009422  \n",
       "3       0.006405       0.036277  \n",
       "4      -0.013425       0.059680  \n",
       "5       0.015335       0.023629  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vectors_path = \"data/semantic_embedding.csv\"\n",
    "word_list_path = \"data/word_list.csv\"\n",
    "concept_path = \"data/concepts.tsv\"\n",
    "\n",
    "vectors = pd.read_csv(vectors_path, header=None)\n",
    "word_list = pd.read_csv(word_list_path, header=None)\n",
    "concept = pd.read_csv(concept_path, sep=\"\\t\")\n",
    "\n",
    "column_category = [\"Bottom-up Category (Human Raters)\",\\\n",
    "                   \"Top-down Category (WordNet)\",\\\n",
    "                   \"Top-down Category (manual selection)\"]\n",
    "concept_list = concept[column_category]\n",
    "\n",
    "word_list.columns = [\"Word\"]\n",
    "vectors.columns = [f\"Dimension_{i}\" for i in range(1, len(vectors.columns)+1)]\n",
    "dataset = pd.concat([word_list, concept_list, vectors], axis=1)\n",
    "dataset.index = range(1, len(dataset)+1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52034536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cluster: select vector columns [Dimension_1 to Dimension_300]\n",
    "column_selected_vector = dataset.columns[4:]\n",
    "dataset_vector = dataset[column_selected_vector] # select only vector columns\n",
    "# Remove rows with NaN values\n",
    "dataset_vector = dataset_vector.loc[~dataset_vector[\"Dimension_1\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd0af3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_vector.isna().sum().sum() # check if there is any NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b306912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=27, random_state=42)\n",
    "clusters = kmeans.fit_predict(dataset_vector)\n",
    "\n",
    "dataset_vector[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64de5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension_1</th>\n",
       "      <th>Dimension_2</th>\n",
       "      <th>Dimension_3</th>\n",
       "      <th>Dimension_4</th>\n",
       "      <th>Dimension_5</th>\n",
       "      <th>Dimension_6</th>\n",
       "      <th>Dimension_7</th>\n",
       "      <th>Dimension_8</th>\n",
       "      <th>Dimension_9</th>\n",
       "      <th>Dimension_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Dimension_292</th>\n",
       "      <th>Dimension_293</th>\n",
       "      <th>Dimension_294</th>\n",
       "      <th>Dimension_295</th>\n",
       "      <th>Dimension_296</th>\n",
       "      <th>Dimension_297</th>\n",
       "      <th>Dimension_298</th>\n",
       "      <th>Dimension_299</th>\n",
       "      <th>Dimension_300</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.068236</td>\n",
       "      <td>-0.028361</td>\n",
       "      <td>0.166795</td>\n",
       "      <td>-0.065438</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.072952</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>-0.011896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011164</td>\n",
       "      <td>-0.005354</td>\n",
       "      <td>0.035327</td>\n",
       "      <td>-0.001382</td>\n",
       "      <td>0.077301</td>\n",
       "      <td>-0.083461</td>\n",
       "      <td>0.064104</td>\n",
       "      <td>-0.004183</td>\n",
       "      <td>0.046304</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056792</td>\n",
       "      <td>-0.063938</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>0.045321</td>\n",
       "      <td>-0.038369</td>\n",
       "      <td>0.048631</td>\n",
       "      <td>0.050771</td>\n",
       "      <td>-0.090274</td>\n",
       "      <td>-0.016943</td>\n",
       "      <td>0.067346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041572</td>\n",
       "      <td>-0.017164</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.051482</td>\n",
       "      <td>-0.040223</td>\n",
       "      <td>-0.066239</td>\n",
       "      <td>0.016329</td>\n",
       "      <td>-0.076589</td>\n",
       "      <td>-0.009422</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027205</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>-0.025440</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>-0.027733</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.069669</td>\n",
       "      <td>-0.036609</td>\n",
       "      <td>0.043710</td>\n",
       "      <td>-0.023415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074330</td>\n",
       "      <td>-0.086789</td>\n",
       "      <td>-0.115503</td>\n",
       "      <td>0.019062</td>\n",
       "      <td>0.069380</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>-0.006804</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.036277</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034074</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>-0.079977</td>\n",
       "      <td>0.064698</td>\n",
       "      <td>-0.002513</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>0.094188</td>\n",
       "      <td>-0.002276</td>\n",
       "      <td>-0.002716</td>\n",
       "      <td>0.128304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023666</td>\n",
       "      <td>-0.046211</td>\n",
       "      <td>-0.060001</td>\n",
       "      <td>0.047634</td>\n",
       "      <td>-0.036336</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>-0.053503</td>\n",
       "      <td>-0.013425</td>\n",
       "      <td>0.059680</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>-0.031035</td>\n",
       "      <td>-0.008351</td>\n",
       "      <td>-0.013928</td>\n",
       "      <td>0.066164</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>-0.052600</td>\n",
       "      <td>0.041855</td>\n",
       "      <td>0.092639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047054</td>\n",
       "      <td>-0.002966</td>\n",
       "      <td>0.038435</td>\n",
       "      <td>0.027077</td>\n",
       "      <td>-0.031518</td>\n",
       "      <td>-0.092717</td>\n",
       "      <td>0.145555</td>\n",
       "      <td>0.015335</td>\n",
       "      <td>0.023629</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>-0.007247</td>\n",
       "      <td>-0.009497</td>\n",
       "      <td>-0.098389</td>\n",
       "      <td>0.014883</td>\n",
       "      <td>-0.074022</td>\n",
       "      <td>-0.034846</td>\n",
       "      <td>0.031211</td>\n",
       "      <td>-0.075538</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>0.065245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112528</td>\n",
       "      <td>-0.085710</td>\n",
       "      <td>-0.013974</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>-0.062135</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>0.035923</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>-0.046959</td>\n",
       "      <td>0.029584</td>\n",
       "      <td>0.026730</td>\n",
       "      <td>-0.007823</td>\n",
       "      <td>-0.048818</td>\n",
       "      <td>-0.022490</td>\n",
       "      <td>0.042724</td>\n",
       "      <td>-0.058452</td>\n",
       "      <td>-0.051158</td>\n",
       "      <td>0.060507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>-0.097171</td>\n",
       "      <td>-0.011267</td>\n",
       "      <td>0.022133</td>\n",
       "      <td>-0.018902</td>\n",
       "      <td>0.015964</td>\n",
       "      <td>-0.019782</td>\n",
       "      <td>0.044278</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>-0.012443</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>-0.115256</td>\n",
       "      <td>0.053251</td>\n",
       "      <td>-0.037307</td>\n",
       "      <td>-0.033384</td>\n",
       "      <td>0.041371</td>\n",
       "      <td>-0.027366</td>\n",
       "      <td>-0.069512</td>\n",
       "      <td>-0.011347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061006</td>\n",
       "      <td>-0.054515</td>\n",
       "      <td>0.034001</td>\n",
       "      <td>0.131828</td>\n",
       "      <td>0.113010</td>\n",
       "      <td>0.030256</td>\n",
       "      <td>0.042306</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>-0.002309</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>-0.023785</td>\n",
       "      <td>0.035685</td>\n",
       "      <td>-0.052391</td>\n",
       "      <td>-0.026013</td>\n",
       "      <td>-0.007483</td>\n",
       "      <td>0.030385</td>\n",
       "      <td>0.060418</td>\n",
       "      <td>-0.001094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>-0.056979</td>\n",
       "      <td>0.045449</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>-0.051059</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>-0.024869</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>0.064542</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>-0.023456</td>\n",
       "      <td>0.103913</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.125297</td>\n",
       "      <td>-0.027692</td>\n",
       "      <td>-0.011931</td>\n",
       "      <td>0.082805</td>\n",
       "      <td>-0.055717</td>\n",
       "      <td>-0.096469</td>\n",
       "      <td>0.074393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027402</td>\n",
       "      <td>-0.074495</td>\n",
       "      <td>-0.045922</td>\n",
       "      <td>0.070159</td>\n",
       "      <td>-0.010379</td>\n",
       "      <td>-0.021651</td>\n",
       "      <td>-0.041719</td>\n",
       "      <td>0.047537</td>\n",
       "      <td>0.078782</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1844 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dimension_1  Dimension_2  Dimension_3  Dimension_4  Dimension_5  \\\n",
       "1        0.002518     0.068236    -0.028361     0.166795    -0.065438   \n",
       "2        0.056792    -0.063938    -0.001322     0.045321    -0.038369   \n",
       "3        0.027205     0.002443    -0.025440     0.022057    -0.027733   \n",
       "4        0.034074     0.006323    -0.079977     0.064698    -0.002513   \n",
       "5        0.001522     0.003388    -0.031035    -0.008351    -0.013928   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1850    -0.007247    -0.009497    -0.098389     0.014883    -0.074022   \n",
       "1851    -0.046959     0.029584     0.026730    -0.007823    -0.048818   \n",
       "1852    -0.012443    -0.002405    -0.115256     0.053251    -0.037307   \n",
       "1853    -0.002309     0.003196    -0.023785     0.035685    -0.052391   \n",
       "1854    -0.023456     0.103913    -0.000789     0.125297    -0.027692   \n",
       "\n",
       "      Dimension_6  Dimension_7  Dimension_8  Dimension_9  Dimension_10  ...  \\\n",
       "1        0.031492     0.072952     0.005569     0.006577     -0.011896  ...   \n",
       "2        0.048631     0.050771    -0.090274    -0.016943      0.067346  ...   \n",
       "3        0.004925     0.069669    -0.036609     0.043710     -0.023415  ...   \n",
       "4       -0.019950     0.094188    -0.002276    -0.002716      0.128304  ...   \n",
       "5        0.066164     0.036939    -0.052600     0.041855      0.092639  ...   \n",
       "...           ...          ...          ...          ...           ...  ...   \n",
       "1850    -0.034846     0.031211    -0.075538     0.023160      0.065245  ...   \n",
       "1851    -0.022490     0.042724    -0.058452    -0.051158      0.060507  ...   \n",
       "1852    -0.033384     0.041371    -0.027366    -0.069512     -0.011347  ...   \n",
       "1853    -0.026013    -0.007483     0.030385     0.060418     -0.001094  ...   \n",
       "1854    -0.011931     0.082805    -0.055717    -0.096469      0.074393  ...   \n",
       "\n",
       "      Dimension_292  Dimension_293  Dimension_294  Dimension_295  \\\n",
       "1          0.011164      -0.005354       0.035327      -0.001382   \n",
       "2          0.041572      -0.017164      -0.052926      -0.051482   \n",
       "3          0.074330      -0.086789      -0.115503       0.019062   \n",
       "4          0.023666      -0.046211      -0.060001       0.047634   \n",
       "5          0.047054      -0.002966       0.038435       0.027077   \n",
       "...             ...            ...            ...            ...   \n",
       "1850       0.112528      -0.085710      -0.013974      -0.015309   \n",
       "1851       0.004924      -0.097171      -0.011267       0.022133   \n",
       "1852       0.061006      -0.054515       0.034001       0.131828   \n",
       "1853       0.004240      -0.056979       0.045449       0.008078   \n",
       "1854      -0.027402      -0.074495      -0.045922       0.070159   \n",
       "\n",
       "      Dimension_296  Dimension_297  Dimension_298  Dimension_299  \\\n",
       "1          0.077301      -0.083461       0.064104      -0.004183   \n",
       "2         -0.040223      -0.066239       0.016329      -0.076589   \n",
       "3          0.069380       0.001089      -0.006804       0.006405   \n",
       "4         -0.036336       0.012826      -0.053503      -0.013425   \n",
       "5         -0.031518      -0.092717       0.145555       0.015335   \n",
       "...             ...            ...            ...            ...   \n",
       "1850      -0.062135      -0.036656      -0.000741       0.035923   \n",
       "1851      -0.018902       0.015964      -0.019782       0.044278   \n",
       "1852       0.113010       0.030256       0.042306       0.012012   \n",
       "1853      -0.051059       0.035830      -0.024869      -0.006122   \n",
       "1854      -0.010379      -0.021651      -0.041719       0.047537   \n",
       "\n",
       "      Dimension_300  cluster  \n",
       "1          0.046304        9  \n",
       "2         -0.009422       25  \n",
       "3          0.036277       13  \n",
       "4          0.059680       11  \n",
       "5          0.023629       19  \n",
       "...             ...      ...  \n",
       "1850       0.008339        5  \n",
       "1851       0.005173       16  \n",
       "1852       0.003221        9  \n",
       "1853       0.064542        6  \n",
       "1854       0.078782       12  \n",
       "\n",
       "[1844 rows x 301 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e0dcac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = dataset_vector[\"cluster\"].unique()\n",
    "\n",
    "dataset[\"cluster\"] = None\n",
    "for i in category:\n",
    "    dataset.loc[dataset_vector[dataset_vector[\"cluster\"]==i].index, \"cluster\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15a65405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bottom-up Category (Human Raters)</th>\n",
       "      <th>Top-down Category (WordNet)</th>\n",
       "      <th>Top-down Category (manual selection)</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>roller coaster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>ferry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>chute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>fishing pole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>blimp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>ready meal</td>\n",
       "      <td>food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>spring roll</td>\n",
       "      <td>food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>food</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>swing set</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>train car</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>tube top</td>\n",
       "      <td>clothing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clothing</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1854 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word Bottom-up Category (Human Raters)  \\\n",
       "1326  roller coaster                               NaN   \n",
       "581            ferry                               NaN   \n",
       "343            chute                               NaN   \n",
       "604     fishing pole                               NaN   \n",
       "140            blimp                               NaN   \n",
       "...              ...                               ...   \n",
       "1293      ready meal                              food   \n",
       "1522     spring roll                              food   \n",
       "1600       swing set                               NaN   \n",
       "1700       train car                           vehicle   \n",
       "1725        tube top                          clothing   \n",
       "\n",
       "     Top-down Category (WordNet) Top-down Category (manual selection) cluster  \n",
       "1326                         NaN                                  NaN       0  \n",
       "581                      vehicle                              vehicle       0  \n",
       "343                          NaN                                  NaN       0  \n",
       "604                          NaN                                  NaN       0  \n",
       "140                      vehicle                                  NaN       0  \n",
       "...                          ...                                  ...     ...  \n",
       "1293                         NaN                                 food    None  \n",
       "1522                         NaN                                 food    None  \n",
       "1600                         NaN                                  NaN    None  \n",
       "1700                         NaN                                  NaN    None  \n",
       "1725                         NaN                             clothing    None  \n",
       "\n",
       "[1854 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cluster = dataset.iloc[:,[0,1,2,3,len(dataset.columns)-1]]\n",
    "dataset_cluster = dataset_cluster.sort_values(by=\"cluster\")\n",
    "dataset_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51832821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_cluster[dataset_cluster[\"cluster\"]==15][\"Word\"].to_csv(\"cluster_weapon.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6779f5",
   "metadata": {},
   "source": [
    "Here, I read one-time output of clustering, cause using K-means to cluster would produce different outputs each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "040ffb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gun\n",
      "landmine\n",
      "lighter\n",
      "flamethrower\n",
      "dynamite\n",
      "fire\n",
      "firecracker\n",
      "firetruck\n",
      "fireworks\n",
      "solar panel\n",
      "extinguisher\n",
      "cannon\n",
      "fire alarm\n",
      "bulldozer\n",
      "blowtorch\n",
      "blowgun\n",
      "rifle\n",
      "grenade\n",
      "catapult\n",
      "rocket\n",
      "trigger\n",
      "detonator\n",
      "shell\n",
      "hail\n",
      "dart\n",
      "missile\n",
      "bazooka\n",
      "cannonball\n",
      "squirt gun\n",
      "revolver\n",
      "tank\n",
      "bullet\n",
      "remote control\n",
      "slingshot\n",
      "torpedo\n",
      "submarine\n",
      "bomb\n",
      "machine gun\n",
      "armor\n",
      "bulletproof vest\n"
     ]
    }
   ],
   "source": [
    "with open(\"cluster_weapon.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ac504",
   "metadata": {},
   "source": [
    "## Based on current exploration + Reflection\n",
    "Clustering is not just a technical step—it is a way of imposing structure on a cultural object. In my case, the “object” is a universe of images (and their concepts) that carry meanings shaped by human experience, cultural categories, and media exposure. Semantic embedding + k-means effectively asks: what counts as “similar” in a learned semantic geometry, and what kinds of meaning neighborhoods does that geometry produce?\n",
    "\n",
    "If the clusters are stable and interpretable, they can become a useful lens for my broader project because they provide a middle layer between raw stimuli and outcomes like memorability. Instead of treating each image as isolated, clustering lets me test whether memorability behaves like a property of semantic neighborhoods: e.g., are certain semantic clusters systematically more memorable because they map to culturally salient themes, threat-related content, novelty schemas, or repeated media motifs? This is aligned with the idea that cultural environments and shared exposure shape what stands out and what gets remembered—clustering helps operationalize that “shared structure” as measurable groups.\n",
    "\n",
    "At the same time, the instability I observed is itself socially meaningful. If k-means partitions change drastically across runs (or across minor preprocessing choices), it suggests the embedding space may not contain strong, consensual boundaries between categories at the granularity I chose (k=27). Substantively, this can be interpreted as: the dataset’s human-coded categories may not correspond to a single coherent semantic taxonomy, or the embedding model is encoding similarity in a way that blurs distinctions humans consider meaningful. That mismatch matters for social science: it reminds us that “semantic similarity” is not a neutral fact—it’s a model-mediated cultural measurement, influenced by what the embedding model saw during training and what cultural regularities it absorbed.\n",
    "\n",
    "This reflection directly informs my next methodological step. If my research question depends on “semantically close groups that are likely together in reality,” then I need to show that those groups are (1) stable, (2) interpretable, and (3) not merely an artifact of forcing k=27. The solution is not to abandon clustering, but to treat clustering results as a claim that must be validated: add stability checks, justify k (or compare multiple k), and potentially adopt a more stable variant (e.g., more restarts, cosine-aware clustering, PCA denoising). This makes my clustering outputs more defensible as a measurement of semantic structure—and therefore more useful for explaining memorability patterns rather than accidentally inventing them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6381b2f4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817af3e",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "Ma, J., Huang, P.-Y., Xie, S., Li, S.-W., Zettlemoyer, L., Chang, S.-F., Yih, W.-T., & Xu, H. (2024). MoDE: CLIP Data Experts via Clustering. 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 26344–26353. https://doi.org/10.1109/CVPR52733.2024.02489\n",
    "\n",
    "Ortakci, Y. (2024). Revolutionary text clustering: Investigating transfer learning capacity of SBERT models through pooling techniques. Engineering Science and Technology, an International Journal, 55, 101730. https://doi.org/10.1016/j.jestch.2024.101730\n",
    "\n",
    "Park, J., Jang, Y., Lee, C., & Lim, H. (2024). Analysis of Utterance Embeddings and Clustering Methods Related to Intent Induction for Task-Oriented Dialogue (No. arXiv:2212.02021). arXiv. https://doi.org/10.48550/arXiv.2212.02021\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
